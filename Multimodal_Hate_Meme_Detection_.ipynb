{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "499d894d735b46879ebd9ad4f2cf6a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50189bc7c39b42fd99a96b4860e59f1e",
              "IPY_MODEL_58513ed0a56e461f845b66dadb7fdfb0",
              "IPY_MODEL_a7f03b034efe4c039b996f618c4c9e18"
            ],
            "layout": "IPY_MODEL_c9cee2f8c4584c4ba5207623cc4ba4f4"
          }
        },
        "50189bc7c39b42fd99a96b4860e59f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_415093831062447cb8989f39180eaddf",
            "placeholder": "​",
            "style": "IPY_MODEL_8237ce4375b844ceac2f884729c6ce71",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "58513ed0a56e461f845b66dadb7fdfb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f06ddb495d40ba9520a7c58e56cf8a",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e686c6f7c1ca4df98ba33da40e243d44",
            "value": 398
          }
        },
        "a7f03b034efe4c039b996f618c4c9e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e612080d8e8c4cb4816690fcb74d6338",
            "placeholder": "​",
            "style": "IPY_MODEL_fc184b1d412c484caae578e7ca746f5d",
            "value": " 398/398 [00:00&lt;00:00, 47.5kB/s]"
          }
        },
        "c9cee2f8c4584c4ba5207623cc4ba4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415093831062447cb8989f39180eaddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8237ce4375b844ceac2f884729c6ce71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78f06ddb495d40ba9520a7c58e56cf8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e686c6f7c1ca4df98ba33da40e243d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e612080d8e8c4cb4816690fcb74d6338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc184b1d412c484caae578e7ca746f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b04fc0280c49739581136b56340707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4315d9d53746477f9da6eebc6c6289a1",
              "IPY_MODEL_3b8851555d224469b25aaac6455f98bb",
              "IPY_MODEL_e2c77650b184402cabfd4fdbd590df65"
            ],
            "layout": "IPY_MODEL_9aba2b5b988e49ca87024253e2dfdf65"
          }
        },
        "4315d9d53746477f9da6eebc6c6289a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7e510d01994d47bb2618f25ec01047",
            "placeholder": "​",
            "style": "IPY_MODEL_1a6c974340f44eb0aef0c0efc5660bb4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3b8851555d224469b25aaac6455f98bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6d5dd1188d499fb7cfa5a71d05d489",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38067ca338cf44f1929151474e9c2862",
            "value": 398
          }
        },
        "e2c77650b184402cabfd4fdbd590df65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67da9b1483c4fe298d57c44bc2602a4",
            "placeholder": "​",
            "style": "IPY_MODEL_4fd20b0c61e746e3b3afd5c9dc8e76bb",
            "value": " 398/398 [00:00&lt;00:00, 46.7kB/s]"
          }
        },
        "9aba2b5b988e49ca87024253e2dfdf65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7e510d01994d47bb2618f25ec01047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6c974340f44eb0aef0c0efc5660bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc6d5dd1188d499fb7cfa5a71d05d489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38067ca338cf44f1929151474e9c2862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e67da9b1483c4fe298d57c44bc2602a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd20b0c61e746e3b3afd5c9dc8e76bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "509645225e8749149f0fcdc700947515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b37911625974fc8893c69cf1a73dc00",
              "IPY_MODEL_9a1ccc495c4b4fec9f4d67b355a7c14c",
              "IPY_MODEL_51d084ff25ca4ab39e23bae680c4dfb3"
            ],
            "layout": "IPY_MODEL_edd459bef86c4ebfaa2c97e221d07c3b"
          }
        },
        "9b37911625974fc8893c69cf1a73dc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01905f3d3a544a189f53f2999e4d87f4",
            "placeholder": "​",
            "style": "IPY_MODEL_1cff49f5bddf415eb362cf5eb4fe1a8a",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "9a1ccc495c4b4fec9f4d67b355a7c14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83bfdb6ee2cb4723831bb9e486ddf95a",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33bb4d81b6c5478bac9a9074fef18b54",
            "value": 5069051
          }
        },
        "51d084ff25ca4ab39e23bae680c4dfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0371a7866bc461cbc4719799b973fdc",
            "placeholder": "​",
            "style": "IPY_MODEL_11201bbb38e34cb29c106a6ef708f372",
            "value": " 5.07M/5.07M [00:01&lt;00:00, 68.5kB/s]"
          }
        },
        "edd459bef86c4ebfaa2c97e221d07c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01905f3d3a544a189f53f2999e4d87f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cff49f5bddf415eb362cf5eb4fe1a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83bfdb6ee2cb4723831bb9e486ddf95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bb4d81b6c5478bac9a9074fef18b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0371a7866bc461cbc4719799b973fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11201bbb38e34cb29c106a6ef708f372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f70cb90d85fd471fb20dde6180711fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36c63785d1c04d48b1a302c0c8975ae8",
              "IPY_MODEL_61c788514bf04063863c511a9ef81002",
              "IPY_MODEL_b840b2e1a8f14e539cd211f25f03c082"
            ],
            "layout": "IPY_MODEL_466d076852ef4139ae54ab5fe9c099c0"
          }
        },
        "36c63785d1c04d48b1a302c0c8975ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_796bcf5b6b3a4c21869a75767a867ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_be33dc0079f7468fb73363087c79f2c6",
            "value": "tokenizer.json: "
          }
        },
        "61c788514bf04063863c511a9ef81002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92caa24411f744eab6e643588013e3ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e925001b7234a4c962552b4e98d8e6b",
            "value": 1
          }
        },
        "b840b2e1a8f14e539cd211f25f03c082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd51c4e6e804e8988a4921805a1b8d6",
            "placeholder": "​",
            "style": "IPY_MODEL_05ef40ebfe10447982c67ef111d0e82f",
            "value": " 9.08M/? [00:00&lt;00:00, 121MB/s]"
          }
        },
        "466d076852ef4139ae54ab5fe9c099c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796bcf5b6b3a4c21869a75767a867ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be33dc0079f7468fb73363087c79f2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92caa24411f744eab6e643588013e3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4e925001b7234a4c962552b4e98d8e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfd51c4e6e804e8988a4921805a1b8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ef40ebfe10447982c67ef111d0e82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7fc3678180949478a1acad787213f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e591e9cd8d349f0921365bbc0f75ed0",
              "IPY_MODEL_fc5e3607b40949c6b8252775af9d474d",
              "IPY_MODEL_a43d8a6ac71a46e3b82a79cf94f73e74"
            ],
            "layout": "IPY_MODEL_1bd963ab9e134c699884de736fb17f3f"
          }
        },
        "3e591e9cd8d349f0921365bbc0f75ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96b4d6145cb46278208d61d036a8714",
            "placeholder": "​",
            "style": "IPY_MODEL_ad44b748e2e449f281f727805fb228f8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "fc5e3607b40949c6b8252775af9d474d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca1a2436bb5c4cd9b2cbfa27c8f2dcad",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df7cd9f744754420bb44b65b2f655ea5",
            "value": 239
          }
        },
        "a43d8a6ac71a46e3b82a79cf94f73e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a341d4aa34004a839c5fb6b0547550d0",
            "placeholder": "​",
            "style": "IPY_MODEL_4effd0879850446096e0e973b91104ae",
            "value": " 239/239 [00:00&lt;00:00, 32.1kB/s]"
          }
        },
        "1bd963ab9e134c699884de736fb17f3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d96b4d6145cb46278208d61d036a8714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad44b748e2e449f281f727805fb228f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca1a2436bb5c4cd9b2cbfa27c8f2dcad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7cd9f744754420bb44b65b2f655ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a341d4aa34004a839c5fb6b0547550d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4effd0879850446096e0e973b91104ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd4d13791f62462f864f59da82e81a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47a362c36eef4b69a0880a69725c97c5",
              "IPY_MODEL_d9bfddc42c564c4a96d9c49418dd7c99",
              "IPY_MODEL_43e0eeca01f54a9898e937c6c5b93928"
            ],
            "layout": "IPY_MODEL_bb0a081a30d34092a5d364a245050900"
          }
        },
        "47a362c36eef4b69a0880a69725c97c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_153a12a0be7d4dfca1f270f20eda473a",
            "placeholder": "​",
            "style": "IPY_MODEL_bdfa7832509748d7a8872e81c3e0835b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d9bfddc42c564c4a96d9c49418dd7c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e1b4a0c78242f7b0563f1c40602fac",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0a86fd58ed746a78fa1e27c480eefe7",
            "value": 398
          }
        },
        "43e0eeca01f54a9898e937c6c5b93928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8c8186782b4577afe328c0ce0ab322",
            "placeholder": "​",
            "style": "IPY_MODEL_e40471a7d6ec4ffeb47f3ad6cd5c19c1",
            "value": " 398/398 [00:00&lt;00:00, 56.0kB/s]"
          }
        },
        "bb0a081a30d34092a5d364a245050900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "153a12a0be7d4dfca1f270f20eda473a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdfa7832509748d7a8872e81c3e0835b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4e1b4a0c78242f7b0563f1c40602fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a86fd58ed746a78fa1e27c480eefe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a8c8186782b4577afe328c0ce0ab322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40471a7d6ec4ffeb47f3ad6cd5c19c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "059561dd44734987a054c89981f09fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bc5ef44448f4470ad2db09f5d85b2f9",
              "IPY_MODEL_e334bb7649ca4ff291a67433bef60b38",
              "IPY_MODEL_a78c707153f24ed39e1f463d6e7802e5"
            ],
            "layout": "IPY_MODEL_da7c9ad011544ec89ff2dadec47d2f67"
          }
        },
        "0bc5ef44448f4470ad2db09f5d85b2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe48e11ec428405591f7326ae5ccf569",
            "placeholder": "​",
            "style": "IPY_MODEL_d1ce91487a8a48eaa11fe9f249c480ab",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e334bb7649ca4ff291a67433bef60b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b2273c025ce4c729aab914dcd767e4c",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e25735470cca4ba5be6a1377941524ee",
            "value": 49
          }
        },
        "a78c707153f24ed39e1f463d6e7802e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4f6a01dc544f288fefd2fbd4ded10e",
            "placeholder": "​",
            "style": "IPY_MODEL_0443267b6ac74722a10053ebb0378125",
            "value": " 49.0/49.0 [00:00&lt;00:00, 6.30kB/s]"
          }
        },
        "da7c9ad011544ec89ff2dadec47d2f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe48e11ec428405591f7326ae5ccf569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ce91487a8a48eaa11fe9f249c480ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b2273c025ce4c729aab914dcd767e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e25735470cca4ba5be6a1377941524ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b4f6a01dc544f288fefd2fbd4ded10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0443267b6ac74722a10053ebb0378125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7bbcff518b4de197d7597875dadf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e45ee93ad8548559fd5ad71db641340",
              "IPY_MODEL_59c9b8f6ee16486eb3b84ef90b94bfbd",
              "IPY_MODEL_b3ed160b23d440e9910273a0f278af41"
            ],
            "layout": "IPY_MODEL_f4953f26598a4c3591f1a38499f4edc5"
          }
        },
        "5e45ee93ad8548559fd5ad71db641340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd5f66c23104f53aaa2aefd033f7df1",
            "placeholder": "​",
            "style": "IPY_MODEL_7f428a8fdeab44f7a5a9e3576b9fbe65",
            "value": "vocab.txt: 100%"
          }
        },
        "59c9b8f6ee16486eb3b84ef90b94bfbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72901d1c8a6415d825ce00b0a92f87b",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acefb77c8a4d47b1a121984a913340e0",
            "value": 995526
          }
        },
        "b3ed160b23d440e9910273a0f278af41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9891c23532480e98a1fadf95e07164",
            "placeholder": "​",
            "style": "IPY_MODEL_4fe7f7873f104d34b30903eef395aa49",
            "value": " 996k/996k [00:00&lt;00:00, 26.9MB/s]"
          }
        },
        "f4953f26598a4c3591f1a38499f4edc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd5f66c23104f53aaa2aefd033f7df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f428a8fdeab44f7a5a9e3576b9fbe65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d72901d1c8a6415d825ce00b0a92f87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acefb77c8a4d47b1a121984a913340e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f9891c23532480e98a1fadf95e07164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe7f7873f104d34b30903eef395aa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aec4bbf8b5049e78a978a4313de7ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd3f83ec7a84475da3082a423829cc26",
              "IPY_MODEL_fb433495c8e8453a9da7aee13d5047ad",
              "IPY_MODEL_aba14c261cd04b2f8dac863c0799d68d"
            ],
            "layout": "IPY_MODEL_0b3d8c0358154825a1b5c2c9a11f0b02"
          }
        },
        "bd3f83ec7a84475da3082a423829cc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ddcaece1c2f4eabaf1583191e85a38f",
            "placeholder": "​",
            "style": "IPY_MODEL_b17dc2d9fcd043d88df1d34f0f37ff72",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "fb433495c8e8453a9da7aee13d5047ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47b117ce5b83487ca3385ca1a3d272af",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64bf1f444f6a42e4a317e4c89a607609",
            "value": 49
          }
        },
        "aba14c261cd04b2f8dac863c0799d68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea652c783a83485cb002efa7dfa78357",
            "placeholder": "​",
            "style": "IPY_MODEL_22cd61caf15d481aaf212d71931bbb6c",
            "value": " 49.0/49.0 [00:00&lt;00:00, 5.56kB/s]"
          }
        },
        "0b3d8c0358154825a1b5c2c9a11f0b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ddcaece1c2f4eabaf1583191e85a38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17dc2d9fcd043d88df1d34f0f37ff72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47b117ce5b83487ca3385ca1a3d272af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64bf1f444f6a42e4a317e4c89a607609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea652c783a83485cb002efa7dfa78357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22cd61caf15d481aaf212d71931bbb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19241de390eb4ec48577c229de4a9cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8ec3dc0a1ae441e864256c1ab60773c",
              "IPY_MODEL_335b663e413740828ff5e029531f6274",
              "IPY_MODEL_a3ee4151aa3343cd992aaf91032e74d8"
            ],
            "layout": "IPY_MODEL_97c4265d364c4139a4d3388defecfab3"
          }
        },
        "a8ec3dc0a1ae441e864256c1ab60773c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e01d58c350b418e9dbb1a266897c650",
            "placeholder": "​",
            "style": "IPY_MODEL_6311d7f295cb44508a548ec14ee54b69",
            "value": "tokenizer.json: 100%"
          }
        },
        "335b663e413740828ff5e029531f6274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_817be48abd944065822620b297e31642",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c75a06d0cc294f828b7dc0e99ab5f251",
            "value": 1961828
          }
        },
        "a3ee4151aa3343cd992aaf91032e74d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f3f55885b24457bf04e0da6ecdfab2",
            "placeholder": "​",
            "style": "IPY_MODEL_2cbee0bc95e34f51b65d4e3f083c8a33",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 7.99MB/s]"
          }
        },
        "97c4265d364c4139a4d3388defecfab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e01d58c350b418e9dbb1a266897c650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6311d7f295cb44508a548ec14ee54b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "817be48abd944065822620b297e31642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75a06d0cc294f828b7dc0e99ab5f251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89f3f55885b24457bf04e0da6ecdfab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbee0bc95e34f51b65d4e3f083c8a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBb_1SK-9O5y",
        "outputId": "d06c78a3-f478-4d0f-aed9-20a36deff2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "GPU cache cleared successfully\n",
            "VRAM allocated: 0.00 GB\n",
            "VRAM reserved: 0.00 GB\n"
          ]
        }
      ],
      "source": [
        "# @title CELL 1.1: Environment Setup\n",
        "from google.colab import drive\n",
        "import os\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "else:\n",
        "    print(\"Drive already mounted at /content/drive\")\n",
        "!pip install -q transformers==4.36.0 sentence-transformers==2.2.2 pyswarm scikit-learn pandas numpy tqdm easyocr\n",
        "import torch, transformers, pandas as pd, numpy as np, json\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Debug CUDA errors\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'   # Enable device-side assertions\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.init()  # Initialize CUDA context\n",
        "    torch.cuda.reset_peak_memory_stats()  # Reset GPU memory stats\n",
        "    torch.cuda.synchronize()  # Ensure GPU operations are complete\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"GPU cache cleared successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not clear GPU cache: {e}\")\n",
        "print(f\"VRAM allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(f\"VRAM reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "os.makedirs('/content/drive/MyDrive/Thesis/output', exist_ok=True)\n",
        "# Setup environment for GPU-accelerated training with CUDA debugging."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 2.1: Load Data\n",
        "df = pd.read_excel('/content/drive/MyDrive/Thesis/dataset/categorized_lexicons.xlsx')\n",
        "df['label'] = df['Label'].map({'Hate': 1, 'Non-hate': 0})\n",
        "df['language'] = df['language'].map({'English': 0, 'Igbo': 1, 'Yoruba': 2, 'Hausa': 3})\n",
        "print(df.shape, df['label'].value_counts(), df['language'].value_counts())\n",
        "# Load and encode dataset (1500 samples)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "00XmfeGL9TJm",
        "outputId": "5052081a-4e17-41af-a417-2b197cea834d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 6) label\n",
            "0    900\n",
            "1    600\n",
            "Name: count, dtype: int64 language\n",
            "0    500\n",
            "2    336\n",
            "1    333\n",
            "3    331\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 2.2: Preprocess Images and Text\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from transformers import AutoTokenizer, DistilBertTokenizer\n",
        "import easyocr\n",
        "import unicodedata\n",
        "import os\n",
        "clip_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.481, 0.457, 0.408), (0.269, 0.271, 0.282))])\n",
        "resnet_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "print(\"Initializing EasyOCR reader...\")\n",
        "reader = easyocr.Reader(['en'], gpu=False)  # Run on CPU to avoid CUDA error\n",
        "print(\"Loading llava_tokenizer...\")\n",
        "llava_tokenizer = AutoTokenizer.from_pretrained('Davlan/afro-xlmr-base', force_download=True)\n",
        "print(\"Loading baseline_tokenizer...\")\n",
        "baseline_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased', force_download=True)\n",
        "df['caption'] = df['caption'].fillna('').astype(str).apply(lambda x: unicodedata.normalize('NFKD', x))  # Normalize captions\n",
        "# Debug: Check for invalid captions and image paths\n",
        "invalid_captions = df['caption'].apply(lambda x: not isinstance(x, str) or len(x.strip()) == 0)\n",
        "invalid_paths = df['image_path'].apply(lambda x: not os.path.exists('/content/drive/MyDrive/Thesis/dataset/images/' + str(x)))\n",
        "if invalid_captions.any():\n",
        "    print(f\"Warning: {invalid_captions.sum()} invalid captions found\")\n",
        "if invalid_paths.any():\n",
        "    print(f\"Warning: {invalid_paths.sum()} invalid image paths found\")\n",
        "print(df[['image_path', 'caption', 'language']].head(10))\n",
        "# Preprocess images and use captions directly."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652,
          "referenced_widgets": [
            "499d894d735b46879ebd9ad4f2cf6a02",
            "50189bc7c39b42fd99a96b4860e59f1e",
            "58513ed0a56e461f845b66dadb7fdfb0",
            "a7f03b034efe4c039b996f618c4c9e18",
            "c9cee2f8c4584c4ba5207623cc4ba4f4",
            "415093831062447cb8989f39180eaddf",
            "8237ce4375b844ceac2f884729c6ce71",
            "78f06ddb495d40ba9520a7c58e56cf8a",
            "e686c6f7c1ca4df98ba33da40e243d44",
            "e612080d8e8c4cb4816690fcb74d6338",
            "fc184b1d412c484caae578e7ca746f5d",
            "a1b04fc0280c49739581136b56340707",
            "4315d9d53746477f9da6eebc6c6289a1",
            "3b8851555d224469b25aaac6455f98bb",
            "e2c77650b184402cabfd4fdbd590df65",
            "9aba2b5b988e49ca87024253e2dfdf65",
            "7e7e510d01994d47bb2618f25ec01047",
            "1a6c974340f44eb0aef0c0efc5660bb4",
            "fc6d5dd1188d499fb7cfa5a71d05d489",
            "38067ca338cf44f1929151474e9c2862",
            "e67da9b1483c4fe298d57c44bc2602a4",
            "4fd20b0c61e746e3b3afd5c9dc8e76bb",
            "509645225e8749149f0fcdc700947515",
            "9b37911625974fc8893c69cf1a73dc00",
            "9a1ccc495c4b4fec9f4d67b355a7c14c",
            "51d084ff25ca4ab39e23bae680c4dfb3",
            "edd459bef86c4ebfaa2c97e221d07c3b",
            "01905f3d3a544a189f53f2999e4d87f4",
            "1cff49f5bddf415eb362cf5eb4fe1a8a",
            "83bfdb6ee2cb4723831bb9e486ddf95a",
            "33bb4d81b6c5478bac9a9074fef18b54",
            "b0371a7866bc461cbc4719799b973fdc",
            "11201bbb38e34cb29c106a6ef708f372",
            "f70cb90d85fd471fb20dde6180711fdf",
            "36c63785d1c04d48b1a302c0c8975ae8",
            "61c788514bf04063863c511a9ef81002",
            "b840b2e1a8f14e539cd211f25f03c082",
            "466d076852ef4139ae54ab5fe9c099c0",
            "796bcf5b6b3a4c21869a75767a867ae6",
            "be33dc0079f7468fb73363087c79f2c6",
            "92caa24411f744eab6e643588013e3ff",
            "4e925001b7234a4c962552b4e98d8e6b",
            "cfd51c4e6e804e8988a4921805a1b8d6",
            "05ef40ebfe10447982c67ef111d0e82f",
            "d7fc3678180949478a1acad787213f79",
            "3e591e9cd8d349f0921365bbc0f75ed0",
            "fc5e3607b40949c6b8252775af9d474d",
            "a43d8a6ac71a46e3b82a79cf94f73e74",
            "1bd963ab9e134c699884de736fb17f3f",
            "d96b4d6145cb46278208d61d036a8714",
            "ad44b748e2e449f281f727805fb228f8",
            "ca1a2436bb5c4cd9b2cbfa27c8f2dcad",
            "df7cd9f744754420bb44b65b2f655ea5",
            "a341d4aa34004a839c5fb6b0547550d0",
            "4effd0879850446096e0e973b91104ae",
            "dd4d13791f62462f864f59da82e81a2c",
            "47a362c36eef4b69a0880a69725c97c5",
            "d9bfddc42c564c4a96d9c49418dd7c99",
            "43e0eeca01f54a9898e937c6c5b93928",
            "bb0a081a30d34092a5d364a245050900",
            "153a12a0be7d4dfca1f270f20eda473a",
            "bdfa7832509748d7a8872e81c3e0835b",
            "c4e1b4a0c78242f7b0563f1c40602fac",
            "f0a86fd58ed746a78fa1e27c480eefe7",
            "1a8c8186782b4577afe328c0ce0ab322",
            "e40471a7d6ec4ffeb47f3ad6cd5c19c1",
            "059561dd44734987a054c89981f09fc4",
            "0bc5ef44448f4470ad2db09f5d85b2f9",
            "e334bb7649ca4ff291a67433bef60b38",
            "a78c707153f24ed39e1f463d6e7802e5",
            "da7c9ad011544ec89ff2dadec47d2f67",
            "fe48e11ec428405591f7326ae5ccf569",
            "d1ce91487a8a48eaa11fe9f249c480ab",
            "6b2273c025ce4c729aab914dcd767e4c",
            "e25735470cca4ba5be6a1377941524ee",
            "8b4f6a01dc544f288fefd2fbd4ded10e",
            "0443267b6ac74722a10053ebb0378125",
            "bd7bbcff518b4de197d7597875dadf4e",
            "5e45ee93ad8548559fd5ad71db641340",
            "59c9b8f6ee16486eb3b84ef90b94bfbd",
            "b3ed160b23d440e9910273a0f278af41",
            "f4953f26598a4c3591f1a38499f4edc5",
            "efd5f66c23104f53aaa2aefd033f7df1",
            "7f428a8fdeab44f7a5a9e3576b9fbe65",
            "d72901d1c8a6415d825ce00b0a92f87b",
            "acefb77c8a4d47b1a121984a913340e0",
            "2f9891c23532480e98a1fadf95e07164",
            "4fe7f7873f104d34b30903eef395aa49",
            "9aec4bbf8b5049e78a978a4313de7ca1",
            "bd3f83ec7a84475da3082a423829cc26",
            "fb433495c8e8453a9da7aee13d5047ad",
            "aba14c261cd04b2f8dac863c0799d68d",
            "0b3d8c0358154825a1b5c2c9a11f0b02",
            "6ddcaece1c2f4eabaf1583191e85a38f",
            "b17dc2d9fcd043d88df1d34f0f37ff72",
            "47b117ce5b83487ca3385ca1a3d272af",
            "64bf1f444f6a42e4a317e4c89a607609",
            "ea652c783a83485cb002efa7dfa78357",
            "22cd61caf15d481aaf212d71931bbb6c",
            "19241de390eb4ec48577c229de4a9cec",
            "a8ec3dc0a1ae441e864256c1ab60773c",
            "335b663e413740828ff5e029531f6274",
            "a3ee4151aa3343cd992aaf91032e74d8",
            "97c4265d364c4139a4d3388defecfab3",
            "6e01d58c350b418e9dbb1a266897c650",
            "6311d7f295cb44508a548ec14ee54b69",
            "817be48abd944065822620b297e31642",
            "c75a06d0cc294f828b7dc0e99ab5f251",
            "89f3f55885b24457bf04e0da6ecdfab2",
            "2cbee0bc95e34f51b65d4e3f083c8a33"
          ]
        },
        "collapsed": true,
        "cellView": "form",
        "id": "fdaAnB_o-1wg",
        "outputId": "2bd56b50-8351-4a04-fae9-41a6ec50a55f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing EasyOCR reader...\n",
            "Loading llava_tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/398 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "499d894d735b46879ebd9ad4f2cf6a02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/398 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1b04fc0280c49739581136b56340707"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "509645225e8749149f0fcdc700947515"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f70cb90d85fd471fb20dde6180711fdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7fc3678180949478a1acad787213f79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/398 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd4d13791f62462f864f59da82e81a2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading baseline_tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "059561dd44734987a054c89981f09fc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd7bbcff518b4de197d7597875dadf4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9aec4bbf8b5049e78a978a4313de7ca1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19241de390eb4ec48577c229de4a9cec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    image_path                        caption  language\n",
            "0   frame1.png                     Inyamụrị         1\n",
            "1   frame2.png                       Ndi ocha         1\n",
            "2   frame3.png                     Umu Aboki          1\n",
            "3   frame4.png      Ndi Yoruba bụ aghụghọ          1\n",
            "4   frame5.png                            Zoo         1\n",
            "5   frame6.png                       Ndị ara         1\n",
            "6   frame7.png              I lụ ụmụ Hausa         1\n",
            "7   frame8.png   Kwụsị ịna-eme ofe mmanụ          1\n",
            "8   frame9.png          Ndi Yoruba egbu anyị         1\n",
            "9  frame10.png    Hapụ ndị na-enweghị isi          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 2.3: Cross-Validation Splits\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "df['stratify'] = df['label'].astype(str) + '_' + df['language'].astype(str)\n",
        "folds = [(train_idx, test_idx) for train_idx, test_idx in skf.split(df, df['stratify'])]\n",
        "print([len(fold[0]) for fold in folds], [len(fold[1]) for fold in folds])\n",
        "# Generate balanced CV splits."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "tHEESKK0-LHD",
        "outputId": "b2f82905-ea31-4d44-d53f-331e29093496"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1200, 1200, 1200, 1200, 1200] [300, 300, 300, 300, 300]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 3.0: Evaluation Function and Models\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import CLIPVisionModel, AutoModel\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    preds, labels, probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            logits = model(batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "            preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "            labels.extend(batch['label'].cpu().numpy())\n",
        "            probs.extend(torch.softmax(logits, dim=1)[:, 1].cpu().numpy())\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, probs)\n",
        "    except:\n",
        "        auc = float('nan')\n",
        "    return acc, prec, rec, f1, auc\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, df, transform, tokenizer):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.tokenizer = tokenizer\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open('/content/drive/MyDrive/Thesis/dataset/images/' + row['image_path']).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        txt = self.tokenizer(row['caption'], padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "        return {'image': img, 'input_ids': txt['input_ids'].squeeze(), 'attention_mask': txt['attention_mask'].squeeze(), 'label': torch.tensor(row['label'], dtype=torch.long)}\n",
        "class LLaVAModel(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.clip = CLIPVisionModel.from_pretrained('openai/clip-vit-base-patch32')\n",
        "        self.afriberta = AutoModel.from_pretrained('Davlan/afro-xlmr-base')\n",
        "        self.proj = nn.Linear(768, 768)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(768, int(params[5])),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(params[4]),\n",
        "            nn.Linear(int(params[5]), 2)\n",
        "        )\n",
        "        self.alpha = nn.Parameter(torch.tensor(0.5))\n",
        "        for p in self.clip.parameters():\n",
        "            p.requires_grad = False\n",
        "        for p in self.afriberta.parameters():\n",
        "            p.requires_grad = False\n",
        "    def forward(self, img, txt, mask):\n",
        "        img_feat = self.clip(img).last_hidden_state[:, 0, :]\n",
        "        img_feat = self.proj(img_feat)\n",
        "        txt_feat = self.afriberta(input_ids=txt, attention_mask=mask).last_hidden_state[:, 0, :]\n",
        "        return self.alpha * self.fc(img_feat) + (1 - self.alpha) * self.fc(txt_feat)\n",
        "# Define evaluation function and LLaVA model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "YTFuWY-lDe9O",
        "outputId": "055a4357-5925-47b0-9008-38cdf698001c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 3.1: PSO Setup\n",
        "from pyswarm import pso\n",
        "from torch.utils.data import DataLoader # Import DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast # Import GradScaler and autocast\n",
        "\n",
        "def objective(params):\n",
        "    lr, flr, clr, wd, dr, hd, bs = params\n",
        "    # Ensure device is defined within the function's scope or is globally accessible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = LLaVAModel(params).to(device)\n",
        "    optimizer = torch.optim.Adam([{'params': model.proj.parameters(), 'lr': lr*flr}, {'params': model.fc.parameters(), 'lr': lr*clr}], weight_decay=wd)\n",
        "    train_df, val_df = df.iloc[folds[0][0]], df.iloc[folds[0][1]]\n",
        "\n",
        "    # Use llava_tokenizer which is defined in cell fdaAnB_o-1wg\n",
        "    train_loader = DataLoader(MemeDataset(train_df, clip_transform, llava_tokenizer), batch_size=int(bs))\n",
        "    val_loader = DataLoader(MemeDataset(val_df, clip_transform, llava_tokenizer), batch_size=int(bs))\n",
        "\n",
        "    model.train()\n",
        "    scaler = GradScaler() # Use imported GradScaler\n",
        "    for epoch in range(2): # Iterate for 2 epochs\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            with autocast(): # Use imported autocast\n",
        "                logits = model(batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "                loss = torch.nn.CrossEntropyLoss()(logits, batch['label'].to(device))\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "    acc, _, _, _, _ = evaluate(model, val_loader)\n",
        "    return -acc\n",
        "\n",
        "# Ensure necessary variables like df, folds, clip_transform, llava_tokenizer, MemeDataset, LLaVAModel, evaluate are defined in previous cells and accessible.\n",
        "\n",
        "lb = [1e-5, 0.1, 0.1, 1e-6, 0.1, 256, 8]\n",
        "ub = [1e-3, 1.0, 1.0, 1e-4, 0.5, 1024, 16]\n",
        "\n",
        "# Check if required variables are defined before calling pso\n",
        "if 'df' in globals() and 'folds' in globals() and 'clip_transform' in globals() and 'llava_tokenizer' in globals() and 'MemeDataset' in globals() and 'LLaVAModel' in globals() and 'evaluate' in globals() and 'device' in globals():\n",
        "    best_params, _ = pso(objective, lb, ub, swarmsize=10, maxiter=12)\n",
        "    print('Best params:', dict(zip(['lr', 'flr', 'clr', 'wd', 'dr', 'hd', 'bs'], best_params)))\n",
        "else:\n",
        "    print(\"Error: Necessary variables for PSO are not defined. Please run previous cells.\")\n",
        "\n",
        "# Optimize LLaVA hyperparameters with 12 iterations."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3Yc8VwaZEv0d",
        "outputId": "568269ef-1866-4540-8b95-be4248975fa0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1766986087.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() # Use imported GradScaler\n",
            "/tmp/ipython-input-1766986087.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(): # Use imported autocast\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping search: maximum iterations reached --> 12\n",
            "Best params: {'lr': np.float64(0.0007524736625526406), 'flr': np.float64(0.22314081292537946), 'clr': np.float64(0.586249349428616), 'wd': np.float64(8.19675420640813e-05), 'dr': np.float64(0.34723101655948285), 'hd': np.float64(417.04264795201635), 'bs': np.float64(11.006986850559457)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 3.1: DISPLAY PSO Result (best_params)\n",
        "best_params = [0.0007620625071926831, 0.5315936642420828, 0.14532729200890485, 6.254705018275373e-05, 0.11767602911626884, 528, 14]\n",
        "print('Best params:', dict(zip(['lr', 'flr', 'clr', 'wd', 'dr', 'hd', 'bs'], best_params)))\n",
        "# Use saved PSO-optimized hyperparameters (lr, flr, clr, wd, dr, hd, bs)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GR0X4krmvnP7",
        "outputId": "a9b57aac-cc65-4bf1-f839-24ed9627889b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'lr': 0.0007620625071926831, 'flr': 0.5315936642420828, 'clr': 0.14532729200890485, 'wd': 6.254705018275373e-05, 'dr': 0.11767602911626884, 'hd': 528, 'bs': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 4.1: Model Definition (Baseline)\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from transformers import DistilBertModel\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        try:\n",
        "            print(\"Clearing GPU cache before ResNet50...\")\n",
        "            torch.cuda.synchronize()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"Loading ResNet50...\")\n",
        "            # Removed torch_dtype=torch.float16\n",
        "            self.resnet = nn.Sequential(*list(resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).children())[:-1])\n",
        "            self.resnet = self.resnet.to(device)\n",
        "            print(\"ResNet50 loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ResNet50: {e}\")\n",
        "            raise\n",
        "        try:\n",
        "            print(\"Clearing GPU cache before DistilBERT...\")\n",
        "            torch.cuda.synchronize()\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"Loading DistilBERT...\")\n",
        "            # Removed torch_dtype=torch.float16\n",
        "            self.distilbert = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
        "            self.distilbert = self.distilbert.to(device)\n",
        "            print(\"DistilBERT loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading DistilBERT: {e}\")\n",
        "            raise\n",
        "        self.img_fc = nn.Sequential(nn.Linear(2048, 512), nn.ReLU(), nn.Dropout(0.4), nn.Linear(512, 2)).to(device)\n",
        "        self.txt_fc = nn.Sequential(nn.Linear(768, 512), nn.ReLU(), nn.Dropout(0.4), nn.Linear(512, 2)).to(device)\n",
        "        self.alpha = nn.Parameter(torch.tensor(0.5, device=device))\n",
        "        for p in self.resnet.parameters():\n",
        "            p.requires_grad = False\n",
        "        for p in self.distilbert.parameters():\n",
        "            p.requires_grad = False\n",
        "    def forward(self, img, txt, mask):\n",
        "        img_feat = self.resnet(img).squeeze()\n",
        "        txt_feat = self.distilbert(input_ids=txt, attention_mask=mask).last_hidden_state[:, 0, :]\n",
        "        return self.alpha * self.img_fc(img_feat) + (1 - self.alpha) * self.txt_fc(txt_feat)\n",
        "print(\"Initializing BaselineModel...\")\n",
        "with torch.no_grad():\n",
        "    model = BaselineModel()\n",
        "print(f\"VRAM after model initialization: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "print(sum(p.numel() for p in model.parameters()))\n",
        "# Define baseline model with Late Fusion."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "XfH5pvp-sP-t",
        "outputId": "e3661208-3ff3-4a40-d8a0-fb205ec8d5e9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing BaselineModel...\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "VRAM after model initialization: 2.58 GB\n",
            "159686981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CELL 4.2: Training Loop (Baseline)\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "scaler = torch.amp.GradScaler('cuda')  # Updated for PyTorch 2.x\n",
        "for fold, (train_idx, test_idx) in enumerate(folds):\n",
        "    train_df, test_df = df.iloc[train_idx], df.iloc[test_idx]\n",
        "    train_dataset = MemeDataset(train_df, resnet_transform, baseline_tokenizer)\n",
        "    test_dataset = MemeDataset(test_df, resnet_transform, baseline_tokenizer)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "    model = BaselineModel().to(device)\n",
        "    optimizer = torch.optim.Adam([{'params': model.parameters(), 'lr': 2e-4}], weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        if epoch == 6:\n",
        "            for p in model.resnet.parameters():\n",
        "                p.requires_grad = True\n",
        "            # Access distilbert attribute of the model instance\n",
        "            for p in model.distilbert.parameters():\n",
        "                p.requires_grad = True\n",
        "        for batch in tqdm(train_loader, desc=f'Fold {fold+1}, Epoch {epoch+1}'):\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast('cuda'):  # Updated for PyTorch 2.x\n",
        "                logits = model(batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "                loss = nn.CrossEntropyLoss()(logits, batch['label'].to(device))\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/Thesis/output/model_fold{fold}.pt')\n",
        "# Train baseline with CV."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "qiAfifeUNcLd",
        "outputId": "b663a555-ad66-4de0-f61e-49fd492a8879"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n",
            "DistilBERT loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 1, Epoch 1: 100%|██████████| 75/75 [00:26<00:00,  2.79it/s]\n",
            "Fold 1, Epoch 2: 100%|██████████| 75/75 [00:25<00:00,  2.90it/s]\n",
            "Fold 1, Epoch 3: 100%|██████████| 75/75 [00:25<00:00,  2.92it/s]\n",
            "Fold 1, Epoch 4: 100%|██████████| 75/75 [00:25<00:00,  2.92it/s]\n",
            "Fold 1, Epoch 5: 100%|██████████| 75/75 [00:25<00:00,  2.92it/s]\n",
            "Fold 1, Epoch 6: 100%|██████████| 75/75 [00:25<00:00,  2.91it/s]\n",
            "Fold 1, Epoch 7: 100%|██████████| 75/75 [01:21<00:00,  1.08s/it]\n",
            "Fold 1, Epoch 8: 100%|██████████| 75/75 [00:36<00:00,  2.08it/s]\n",
            "Fold 1, Epoch 9: 100%|██████████| 75/75 [00:35<00:00,  2.10it/s]\n",
            "Fold 1, Epoch 10: 100%|██████████| 75/75 [00:36<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n",
            "DistilBERT loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 2, Epoch 1: 100%|██████████| 75/75 [00:28<00:00,  2.66it/s]\n",
            "Fold 2, Epoch 2: 100%|██████████| 75/75 [00:25<00:00,  2.89it/s]\n",
            "Fold 2, Epoch 3: 100%|██████████| 75/75 [00:25<00:00,  2.90it/s]\n",
            "Fold 2, Epoch 4: 100%|██████████| 75/75 [00:25<00:00,  2.90it/s]\n",
            "Fold 2, Epoch 5: 100%|██████████| 75/75 [00:25<00:00,  2.90it/s]\n",
            "Fold 2, Epoch 6: 100%|██████████| 75/75 [00:25<00:00,  2.92it/s]\n",
            "Fold 2, Epoch 7: 100%|██████████| 75/75 [00:35<00:00,  2.10it/s]\n",
            "Fold 2, Epoch 8: 100%|██████████| 75/75 [00:35<00:00,  2.09it/s]\n",
            "Fold 2, Epoch 9: 100%|██████████| 75/75 [00:35<00:00,  2.10it/s]\n",
            "Fold 2, Epoch 10: 100%|██████████| 75/75 [00:35<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n",
            "DistilBERT loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 3, Epoch 1: 100%|██████████| 75/75 [00:26<00:00,  2.85it/s]\n",
            "Fold 3, Epoch 2: 100%|██████████| 75/75 [00:25<00:00,  2.90it/s]\n",
            "Fold 3, Epoch 3: 100%|██████████| 75/75 [00:26<00:00,  2.87it/s]\n",
            "Fold 3, Epoch 4: 100%|██████████| 75/75 [00:26<00:00,  2.86it/s]\n",
            "Fold 3, Epoch 5: 100%|██████████| 75/75 [00:26<00:00,  2.87it/s]\n",
            "Fold 3, Epoch 6: 100%|██████████| 75/75 [00:26<00:00,  2.87it/s]\n",
            "Fold 3, Epoch 7: 100%|██████████| 75/75 [00:36<00:00,  2.08it/s]\n",
            "Fold 3, Epoch 8: 100%|██████████| 75/75 [00:35<00:00,  2.09it/s]\n",
            "Fold 3, Epoch 9: 100%|██████████| 75/75 [00:35<00:00,  2.09it/s]\n",
            "Fold 3, Epoch 10: 100%|██████████| 75/75 [00:35<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n",
            "DistilBERT loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 4, Epoch 1: 100%|██████████| 75/75 [00:26<00:00,  2.82it/s]\n",
            "Fold 4, Epoch 2: 100%|██████████| 75/75 [00:25<00:00,  2.89it/s]\n",
            "Fold 4, Epoch 3: 100%|██████████| 75/75 [00:25<00:00,  2.89it/s]\n",
            "Fold 4, Epoch 4: 100%|██████████| 75/75 [00:26<00:00,  2.87it/s]\n",
            "Fold 4, Epoch 5: 100%|██████████| 75/75 [00:25<00:00,  2.91it/s]\n",
            "Fold 4, Epoch 6: 100%|██████████| 75/75 [00:25<00:00,  2.90it/s]\n",
            "Fold 4, Epoch 7: 100%|██████████| 75/75 [00:35<00:00,  2.08it/s]\n",
            "Fold 4, Epoch 8: 100%|██████████| 75/75 [00:36<00:00,  2.08it/s]\n",
            "Fold 4, Epoch 9: 100%|██████████| 75/75 [00:36<00:00,  2.07it/s]\n",
            "Fold 4, Epoch 10: 100%|██████████| 75/75 [00:36<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n",
            "DistilBERT loaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 5, Epoch 1: 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 5, Epoch 2: 100%|██████████| 75/75 [00:25<00:00,  2.89it/s]\n",
            "Fold 5, Epoch 3: 100%|██████████| 75/75 [00:25<00:00,  2.89it/s]\n",
            "Fold 5, Epoch 4: 100%|██████████| 75/75 [00:26<00:00,  2.88it/s]\n",
            "Fold 5, Epoch 5: 100%|██████████| 75/75 [00:25<00:00,  2.89it/s]\n",
            "Fold 5, Epoch 6: 100%|██████████| 75/75 [00:25<00:00,  2.89it/s]\n",
            "Fold 5, Epoch 7: 100%|██████████| 75/75 [00:35<00:00,  2.09it/s]\n",
            "Fold 5, Epoch 8: 100%|██████████| 75/75 [00:35<00:00,  2.09it/s]\n",
            "Fold 5, Epoch 9: 100%|██████████| 75/75 [00:36<00:00,  2.08it/s]\n",
            "Fold 5, Epoch 10: 100%|██████████| 75/75 [00:36<00:00,  2.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4.3: Evaluation (Baseline)\n",
        "results = []\n",
        "for fold, (_, test_idx) in enumerate(folds):\n",
        "    test_df = df.iloc[test_idx]\n",
        "    print(f\"Fold {fold+1} test set language distribution:\\n{test_df['language'].value_counts()}\")\n",
        "    test_dataset = MemeDataset(test_df, resnet_transform, baseline_tokenizer)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8)\n",
        "    model = BaselineModel()\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(f'/content/drive/MyDrive/Thesis/output/model_fold{fold}.pt'))\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model for fold {fold+1}: {e}\")\n",
        "        continue\n",
        "    acc, prec, rec, f1, auc = evaluate(model, test_loader)\n",
        "    lang_results = {}\n",
        "    for i, lang in enumerate(['English', 'Igbo', 'Yoruba', 'Hausa']):\n",
        "        lang_df = test_df[test_df['language'] == i]\n",
        "        if len(lang_df) > 0:\n",
        "            lang_dataset = MemeDataset(lang_df, resnet_transform, baseline_tokenizer)\n",
        "            lang_loader = DataLoader(lang_dataset, batch_size=min(8, len(lang_df)))\n",
        "            try:\n",
        "                metrics = evaluate(model, lang_loader)\n",
        "                lang_results[lang] = metrics\n",
        "                print(f\"Fold {fold+1}, {lang}: acc={metrics[0]:.4f}, prec={metrics[1]:.4f}, rec={metrics[2]:.4f}, f1={metrics[3]:.4f}, auc={metrics[4]:.4f}, samples={len(lang_df)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error evaluating {lang} in fold {fold+1}: {e}\")\n",
        "                lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "        else:\n",
        "            print(f\"No samples for {lang} in fold {fold+1}\")\n",
        "            lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "    results.append({\n",
        "        'fold': fold+1,\n",
        "        'acc': acc,\n",
        "        'prec': prec,\n",
        "        'rec': rec,\n",
        "        'f1': f1,\n",
        "        'auc': auc,\n",
        "        'lang': lang_results,\n",
        "        'f1_std': np.std([lang_results[l][3] for l in lang_results if lang_results[l][3] != 0.0]) if any(lang_results[l][3] != 0.0 for l in lang_results) else 0.0\n",
        "    })\n",
        "# Fallback: Evaluate each language globally\n",
        "global_lang_results = {}\n",
        "for i, lang in enumerate(['English', 'Igbo', 'Yoruba', 'Hausa']):\n",
        "    lang_df = df[df['language'] == i]\n",
        "    if len(lang_df) > 0:\n",
        "        lang_dataset = MemeDataset(lang_df, resnet_transform, baseline_tokenizer)\n",
        "        lang_loader = DataLoader(lang_dataset, batch_size=min(8, len(lang_df)))\n",
        "        model = BaselineModel()\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(f'/content/drive/MyDrive/Thesis/output/model_fold0.pt'))\n",
        "            metrics = evaluate(model, lang_loader)\n",
        "            global_lang_results[lang] = metrics\n",
        "            print(f\"Global {lang}: acc={metrics[0]:.4f}, prec={metrics[1]:.4f}, rec={metrics[2]:.4f}, f1={metrics[3]:.4f}, auc={metrics[4]:.4f}, samples={len(lang_df)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating global {lang}: {e}\")\n",
        "            global_lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "    else:\n",
        "        print(f\"No global samples for {lang}\")\n",
        "        global_lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "print(\"Global language results:\", {k: f\"acc={v[0]:.4f}, prec={v[1]:.4f}, rec={v[2]:.4f}, f1={v[3]:.4f}, auc={v[4]:.4f}\" for k, v in global_lang_results.items()})\n",
        "print(pd.DataFrame(results))\n",
        "# Save results\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/Thesis/output/results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "with open('/content/drive/MyDrive/Thesis/output/global_lang_results.pkl', 'wb') as f:\n",
        "    pickle.dump(global_lang_results, f)\n",
        "# Evaluate baseline performance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFSM5QAOkDSz",
        "outputId": "8c343824-c4f8-4960-c725-8436b84d0b99"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "2     67\n",
            "3     66\n",
            "Name: count, dtype: int64\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Fold 1, English: acc=0.2800, prec=0.2786, rec=0.2800, f1=0.2788, auc=0.2468, samples=100\n",
            "Fold 1, Igbo: acc=0.9104, prec=0.9104, rec=0.9104, f1=0.9095, auc=0.9477, samples=67\n",
            "Fold 1, Yoruba: acc=0.9254, prec=0.9269, rec=0.9254, f1=0.9240, auc=0.9733, samples=67\n",
            "Fold 1, Hausa: acc=0.9394, prec=0.9401, rec=0.9394, f1=0.9388, auc=0.9871, samples=66\n",
            "Fold 2 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "3     67\n",
            "2     66\n",
            "Name: count, dtype: int64\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Fold 2, English: acc=0.4000, prec=0.4000, rec=0.4000, f1=0.4000, auc=0.3200, samples=100\n",
            "Fold 2, Igbo: acc=0.9254, prec=0.9330, rec=0.9254, f1=0.9228, auc=0.9773, samples=67\n",
            "Fold 2, Yoruba: acc=0.9242, prec=0.9239, rec=0.9242, f1=0.9238, auc=0.9666, samples=66\n",
            "Fold 2, Hausa: acc=0.9104, prec=0.9104, rec=0.9104, f1=0.9095, auc=0.9806, samples=67\n",
            "Fold 3 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "2     67\n",
            "3     66\n",
            "Name: count, dtype: int64\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Fold 3, English: acc=0.4100, prec=0.4097, rec=0.4100, f1=0.4095, auc=0.3640, samples=100\n",
            "Fold 3, Igbo: acc=0.9552, prec=0.9552, rec=0.9552, f1=0.9550, auc=0.9951, samples=67\n",
            "Fold 3, Yoruba: acc=0.9552, prec=0.9561, rec=0.9552, f1=0.9554, auc=0.9911, samples=67\n",
            "Fold 3, Hausa: acc=0.9394, prec=0.9394, rec=0.9394, f1=0.9394, auc=0.9939, samples=66\n",
            "Fold 4 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "2     68\n",
            "1     66\n",
            "3     66\n",
            "Name: count, dtype: int64\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Fold 4, English: acc=0.3600, prec=0.3514, rec=0.3600, f1=0.3506, auc=0.2804, samples=100\n",
            "Fold 4, Igbo: acc=0.9394, prec=0.9423, rec=0.9394, f1=0.9399, auc=0.9889, samples=66\n",
            "Fold 4, Yoruba: acc=0.9559, prec=0.9567, rec=0.9559, f1=0.9561, auc=0.9981, samples=68\n",
            "Fold 4, Hausa: acc=0.9394, prec=0.9423, rec=0.9394, f1=0.9399, auc=0.9960, samples=66\n",
            "Fold 5 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "2     68\n",
            "1     66\n",
            "3     66\n",
            "Name: count, dtype: int64\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Fold 5, English: acc=0.4600, prec=0.4322, rec=0.4600, f1=0.3984, auc=0.2864, samples=100\n",
            "Fold 5, Igbo: acc=0.8788, prec=0.8891, rec=0.8788, f1=0.8807, auc=0.9353, samples=66\n",
            "Fold 5, Yoruba: acc=0.8971, prec=0.8964, rec=0.8971, f1=0.8965, auc=0.9801, samples=68\n",
            "Fold 5, Hausa: acc=0.9394, prec=0.9423, rec=0.9394, f1=0.9399, auc=0.9727, samples=66\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Global English: acc=0.8460, prec=0.8463, rec=0.8460, f1=0.8460, auc=0.9145, samples=500\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Global Igbo: acc=0.9790, prec=0.9790, rec=0.9790, f1=0.9789, auc=0.9938, samples=333\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Global Yoruba: acc=0.9851, prec=0.9852, rec=0.9851, f1=0.9851, auc=0.9975, samples=336\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Global Hausa: acc=0.9879, prec=0.9879, rec=0.9879, f1=0.9879, auc=0.9991, samples=331\n",
            "Global language results: {'English': 'acc=0.8460, prec=0.8463, rec=0.8460, f1=0.8460, auc=0.9145', 'Igbo': 'acc=0.9790, prec=0.9790, rec=0.9790, f1=0.9789, auc=0.9938', 'Yoruba': 'acc=0.9851, prec=0.9852, rec=0.9851, f1=0.9851, auc=0.9975', 'Hausa': 'acc=0.9879, prec=0.9879, rec=0.9879, f1=0.9879, auc=0.9991'}\n",
            "   fold       acc      prec       rec        f1       auc  \\\n",
            "0     1  0.710000  0.706789  0.710000  0.707418  0.833880   \n",
            "1     2  0.746667  0.744529  0.746667  0.745052  0.813750   \n",
            "2     3  0.770000  0.771097  0.770000  0.770471  0.873392   \n",
            "3     4  0.750000  0.758945  0.750000  0.752073  0.849491   \n",
            "4     5  0.756667  0.784348  0.756667  0.758981  0.831944   \n",
            "\n",
            "                                                lang    f1_std  \n",
            "0  {'English': (0.28, 0.2785829307568438, 0.28, 0...  0.279595  \n",
            "1  {'English': (0.4, 0.4, 0.4, 0.4, 0.32000000000...  0.224687  \n",
            "2  {'English': (0.41, 0.4096748293857888, 0.41, 0...  0.234119  \n",
            "3  {'English': (0.36, 0.35144312393887944, 0.36, ...  0.257583  \n",
            "4  {'English': (0.46, 0.4322493224932249, 0.46, 0...  0.220746  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4.3: Evaluation (Baseline)\n",
        "results = []\n",
        "for fold, (_, test_idx) in enumerate(folds):\n",
        "    test_df = df.iloc[test_idx]\n",
        "    test_dataset = MemeDataset(test_df, resnet_transform, baseline_tokenizer)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=12)\n",
        "    model = BaselineModel()\n",
        "    model.load_state_dict(torch.load(f'/content/drive/MyDrive/Thesis/output/model_fold{fold}.pt'))\n",
        "    acc, prec, rec, f1, auc = evaluate(model, test_loader)\n",
        "    lang_results = {lang: evaluate(model, DataLoader(MemeDataset(test_df[test_df['language'] == i], resnet_transform, baseline_tokenizer), batch_size=12)) for i, lang in enumerate(['English', 'Igbo', 'Yoruba', 'Hausa']) if len(test_df[test_df['language'] == i]) > 0}\n",
        "    results.append({'fold': fold+1, 'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'auc': auc, 'lang': lang_results, 'f1_std': np.std([lang_results[l][3] for l in lang_results] if lang_results else 0)})\n",
        "print(pd.DataFrame(results))\n",
        "# Evaluate baseline performance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20LsKBS9cOFa",
        "outputId": "4b9ef87a-1203-44e5-8f3d-2094aa9bd427"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n",
            "DistilBERT loaded successfully\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "   fold       acc      prec       rec        f1       auc  \\\n",
            "0     1  0.710000  0.706789  0.710000  0.707418  0.833926   \n",
            "1     2  0.746667  0.744529  0.746667  0.745052  0.813657   \n",
            "2     3  0.770000  0.771097  0.770000  0.770471  0.873346   \n",
            "3     4  0.750000  0.758945  0.750000  0.752073  0.849444   \n",
            "4     5  0.756667  0.784348  0.756667  0.758981  0.832037   \n",
            "\n",
            "                                                lang    f1_std  \n",
            "0  {'English': (0.28, 0.2785829307568438, 0.28, 0...  0.279595  \n",
            "1  {'English': (0.4, 0.4, 0.4, 0.4, 0.31960000000...  0.224687  \n",
            "2  {'English': (0.41, 0.4096748293857888, 0.41, 0...  0.234119  \n",
            "3  {'English': (0.36, 0.35144312393887944, 0.36, ...  0.257583  \n",
            "4  {'English': (0.46, 0.4322493224932249, 0.46, 0...  0.220746  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5.1: Model Definition (LLaVA)\n",
        "model = LLaVAModel(best_params).to(device)\n",
        "print(sum(p.numel() for p in model.parameters()))\n",
        "# Define LLaVA-inspired model for classification."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMgEZcLakemr",
        "outputId": "4cbd34c2-1f73-48ce-d4e6-e574d3b4bc7c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "366497331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5.2: Training Loop (LLaVA with PSO)\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "for fold, (train_idx, test_idx) in enumerate(folds):\n",
        "    train_df, test_df = df.iloc[train_idx], df.iloc[test_idx]\n",
        "    train_dataset = MemeDataset(train_df, clip_transform, llava_tokenizer)\n",
        "    test_dataset = MemeDataset(test_df, clip_transform, llava_tokenizer)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=min(int(best_params[6]), len(train_dataset)), shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=min(int(best_params[6]), len(test_dataset)))\n",
        "    model = LLaVAModel(best_params).to(device)\n",
        "    optimizer = torch.optim.Adam([{'params': model.proj.parameters(), 'lr': best_params[0]*best_params[1]}, {'params': model.fc.parameters(), 'lr': best_params[0]*best_params[2]}], weight_decay=best_params[3])\n",
        "    for epoch in range(8):\n",
        "        model.train()\n",
        "        if epoch == 5:\n",
        "            for p in model.proj.parameters():\n",
        "                p.requires_grad = True\n",
        "            for p in model.fc.parameters():\n",
        "                p.requires_grad = True\n",
        "        for batch in tqdm(train_loader, desc=f'Fold {fold+1}, Epoch {epoch+1} (PSO)'):\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "                loss = nn.CrossEntropyLoss()(logits, batch['label'].to(device))\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/Thesis/output/llava_pso_fold{fold}.pt')\n",
        "# Train LLaVA with PSO-optimized hyperparameters."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NpQjaE3kjwi",
        "outputId": "d19fc8ea-3e69-444b-a674-82108807769f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 1, Epoch 1 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.04it/s]\n",
            "Fold 1, Epoch 2 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.05it/s]\n",
            "Fold 1, Epoch 3 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.07it/s]\n",
            "Fold 1, Epoch 4 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Fold 1, Epoch 5 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Fold 1, Epoch 6 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Fold 1, Epoch 7 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Fold 1, Epoch 8 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.08it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 2, Epoch 1 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.02it/s]\n",
            "Fold 2, Epoch 2 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.06it/s]\n",
            "Fold 2, Epoch 3 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Fold 2, Epoch 4 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.10it/s]\n",
            "Fold 2, Epoch 5 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Fold 2, Epoch 6 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.10it/s]\n",
            "Fold 2, Epoch 7 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Fold 2, Epoch 8 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 3, Epoch 1 (PSO): 100%|██████████| 86/86 [00:29<00:00,  2.89it/s]\n",
            "Fold 3, Epoch 2 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.06it/s]\n",
            "Fold 3, Epoch 3 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.05it/s]\n",
            "Fold 3, Epoch 4 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.06it/s]\n",
            "Fold 3, Epoch 5 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.10it/s]\n",
            "Fold 3, Epoch 6 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.08it/s]\n",
            "Fold 3, Epoch 7 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.06it/s]\n",
            "Fold 3, Epoch 8 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.06it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 4, Epoch 1 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.03it/s]\n",
            "Fold 4, Epoch 2 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.06it/s]\n",
            "Fold 4, Epoch 3 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.11it/s]\n",
            "Fold 4, Epoch 4 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.11it/s]\n",
            "Fold 4, Epoch 5 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.10it/s]\n",
            "Fold 4, Epoch 6 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.10it/s]\n",
            "Fold 4, Epoch 7 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.11it/s]\n",
            "Fold 4, Epoch 8 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.09it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 5, Epoch 1 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.02it/s]\n",
            "Fold 5, Epoch 2 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.04it/s]\n",
            "Fold 5, Epoch 3 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.06it/s]\n",
            "Fold 5, Epoch 4 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.07it/s]\n",
            "Fold 5, Epoch 5 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.08it/s]\n",
            "Fold 5, Epoch 6 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.08it/s]\n",
            "Fold 5, Epoch 7 (PSO): 100%|██████████| 86/86 [00:28<00:00,  3.07it/s]\n",
            "Fold 5, Epoch 8 (PSO): 100%|██████████| 86/86 [00:27<00:00,  3.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5.3: Evaluation (LLaVA with PSO)\n",
        "llava_pso_results = []\n",
        "for fold, (_, test_idx) in enumerate(folds):\n",
        "    test_df = df.iloc[test_idx]\n",
        "    print(f\"Fold {fold+1} test set language distribution:\\n{test_df['language'].value_counts()}\")\n",
        "    test_dataset = MemeDataset(test_df, clip_transform, llava_tokenizer)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=min(int(best_params[6]), len(test_dataset)))\n",
        "    model = LLaVAModel(best_params).to(device)\n",
        "    model.load_state_dict(torch.load(f'/content/drive/MyDrive/Thesis/output/llava_pso_fold{fold}.pt'))\n",
        "    acc, prec, rec, f1, auc = evaluate(model, test_loader)\n",
        "    lang_results = {}\n",
        "    for i, lang in enumerate(['English', 'Igbo', 'Yoruba', 'Hausa']):\n",
        "        lang_df = test_df[test_df['language'] == i]\n",
        "        if len(lang_df) > 0:\n",
        "            lang_dataset = MemeDataset(lang_df, clip_transform, llava_tokenizer)\n",
        "            lang_loader = DataLoader(lang_dataset, batch_size=min(int(best_params[6]), len(lang_df)))\n",
        "            try:\n",
        "                metrics = evaluate(model, lang_loader)\n",
        "                lang_results[lang] = metrics\n",
        "                print(f\"Fold {fold+1}, {lang}: acc={metrics[0]:.4f}, prec={metrics[1]:.4f}, rec={metrics[2]:.4f}, f1={metrics[3]:.4f}, auc={metrics[4]:.4f}, samples={len(lang_df)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error evaluating {lang} in fold {fold+1}: {e}\")\n",
        "                lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "        else:\n",
        "            print(f\"No samples for {lang} in fold {fold+1}\")\n",
        "            lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "    llava_pso_results.append({\n",
        "        'fold': fold+1,\n",
        "        'acc': acc,\n",
        "        'prec': prec,\n",
        "        'rec': rec,\n",
        "        'f1': f1,\n",
        "        'auc': auc,\n",
        "        'lang': lang_results,\n",
        "        'f1_std': np.std([lang_results[l][3] for l in lang_results if lang_results[l][3] != 0.0]) if any(lang_results[l][3] != 0.0 for l in lang_results) else 0.0\n",
        "    })\n",
        "# Fallback: Global evaluation for LLaVA\n",
        "global_llava_results = {}\n",
        "for i, lang in enumerate(['English', 'Igbo', 'Yoruba', 'Hausa']):\n",
        "    lang_df = df[df['language'] == i]\n",
        "    if len(lang_df) > 0:\n",
        "        lang_dataset = MemeDataset(lang_df, clip_transform, llava_tokenizer)\n",
        "        lang_loader = DataLoader(lang_dataset, batch_size=min(int(best_params[6]), len(lang_df)))\n",
        "        model = LLaVAModel(best_params).to(device)\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(f'/content/drive/MyDrive/Thesis/output/llava_pso_fold0.pt'))\n",
        "            metrics = evaluate(model, lang_loader)\n",
        "            global_llava_results[lang] = metrics\n",
        "            print(f\"Global {lang}: acc={metrics[0]:.4f}, prec={metrics[1]:.4f}, rec={metrics[2]:.4f}, f1={metrics[3]:.4f}, auc={metrics[4]:.4f}, samples={len(lang_df)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating global {lang}: {e}\")\n",
        "            global_llava_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "    else:\n",
        "        print(f\"No global samples for {lang}\")\n",
        "        global_llava_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "print(\"Global LLaVA results:\", {k: f\"acc={v[0]:.4f}, prec={v[1]:.4f}, rec={v[2]:.4f}, f1={v[3]:.4f}, auc={v[4]:.4f}\" for k, v in global_llava_results.items()})\n",
        "print(pd.DataFrame(llava_pso_results))\n",
        "# Save results\n",
        "with open('/content/drive/MyDrive/Thesis/output/llava_pso_results.pkl', 'wb') as f:\n",
        "    pickle.dump(llava_pso_results, f)\n",
        "with open('/content/drive/MyDrive/Thesis/output/global_llava_results.pkl', 'wb') as f:\n",
        "    pickle.dump(global_llava_results, f)\n",
        "# Evaluate LLaVA with PSO performance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f3crhwBipPMM",
        "outputId": "96ffb4f3-c27e-4476-e021-b5bead520103"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "2     67\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1, English: acc=0.4700, prec=0.4690, rec=0.4700, f1=0.4657, auc=0.4976, samples=100\n",
            "Fold 1, Igbo: acc=0.8806, prec=0.8822, rec=0.8806, f1=0.8778, auc=0.9380, samples=67\n",
            "Fold 1, Yoruba: acc=0.9552, prec=0.9581, rec=0.9552, f1=0.9544, auc=0.9970, samples=67\n",
            "Fold 1, Hausa: acc=0.8485, prec=0.8486, rec=0.8485, f1=0.8450, auc=0.9563, samples=66\n",
            "Fold 2 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "3     67\n",
            "2     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2, English: acc=0.4200, prec=0.4151, rec=0.4200, f1=0.4115, auc=0.4572, samples=100\n",
            "Fold 2, Igbo: acc=0.8358, prec=0.8356, rec=0.8358, f1=0.8302, auc=0.9229, samples=67\n",
            "Fold 2, Yoruba: acc=0.8939, prec=0.8933, rec=0.8939, f1=0.8934, auc=0.9737, samples=66\n",
            "Fold 2, Hausa: acc=0.9851, prec=0.9857, rec=0.9851, f1=0.9851, auc=0.9961, samples=67\n",
            "Fold 3 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "2     67\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3, English: acc=0.5700, prec=0.5703, rec=0.5700, f1=0.5696, auc=0.5788, samples=100\n",
            "Fold 3, Igbo: acc=0.9104, prec=0.9138, rec=0.9104, f1=0.9113, auc=0.9832, samples=67\n",
            "Fold 3, Yoruba: acc=0.9104, prec=0.9200, rec=0.9104, f1=0.9119, auc=0.9862, samples=67\n",
            "Fold 3, Hausa: acc=0.9242, prec=0.9254, rec=0.9242, f1=0.9246, auc=0.9697, samples=66\n",
            "Fold 4 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "2     68\n",
            "1     66\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4, English: acc=0.4500, prec=0.4475, rec=0.4500, f1=0.4433, auc=0.4488, samples=100\n",
            "Fold 4, Igbo: acc=0.8485, prec=0.8479, rec=0.8485, f1=0.8446, auc=0.9596, samples=66\n",
            "Fold 4, Yoruba: acc=0.9559, prec=0.9559, rec=0.9559, f1=0.9557, auc=0.9896, samples=68\n",
            "Fold 4, Hausa: acc=0.8485, prec=0.8618, rec=0.8485, f1=0.8390, auc=0.9333, samples=66\n",
            "Fold 5 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "2     68\n",
            "1     66\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5, English: acc=0.5900, prec=0.5989, rec=0.5900, f1=0.5806, auc=0.5664, samples=100\n",
            "Fold 5, Igbo: acc=0.8788, prec=0.8864, rec=0.8788, f1=0.8736, auc=0.9585, samples=66\n",
            "Fold 5, Yoruba: acc=0.9118, prec=0.9118, rec=0.9118, f1=0.9118, auc=0.9830, samples=68\n",
            "Fold 5, Hausa: acc=0.7879, prec=0.8205, rec=0.7879, f1=0.7927, auc=0.9191, samples=66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global English: acc=0.8080, prec=0.8087, rec=0.8080, f1=0.8079, auc=0.8705, samples=500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Igbo: acc=0.9309, prec=0.9337, rec=0.9309, f1=0.9295, auc=0.9840, samples=333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Yoruba: acc=0.9821, prec=0.9826, rec=0.9821, f1=0.9820, auc=0.9995, samples=336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Hausa: acc=0.9305, prec=0.9317, rec=0.9305, f1=0.9295, auc=0.9913, samples=331\n",
            "Global LLaVA results: {'English': 'acc=0.8080, prec=0.8087, rec=0.8080, f1=0.8079, auc=0.8705', 'Igbo': 'acc=0.9309, prec=0.9337, rec=0.9309, f1=0.9295, auc=0.9840', 'Yoruba': 'acc=0.9821, prec=0.9826, rec=0.9821, f1=0.9820, auc=0.9995', 'Hausa': 'acc=0.9305, prec=0.9317, rec=0.9305, f1=0.9295, auc=0.9913'}\n",
            "   fold       acc      prec       rec        f1       auc  \\\n",
            "0     1  0.753333  0.751257  0.753333  0.748748  0.859873   \n",
            "1     2  0.743333  0.746329  0.743333  0.744425  0.847778   \n",
            "2     3  0.800000  0.804171  0.800000  0.801191  0.901063   \n",
            "3     4  0.740000  0.739318  0.740000  0.739626  0.845509   \n",
            "4     5  0.770000  0.778747  0.770000  0.771907  0.855139   \n",
            "\n",
            "                                                lang    f1_std  \n",
            "0  {'English': (0.47, 0.4689954526663911, 0.47, 0...  0.189001  \n",
            "1  {'English': (0.42, 0.4151103565365025, 0.42, 0...  0.219790  \n",
            "2  {'English': (0.57, 0.5702529104777199, 0.57, 0...  0.150052  \n",
            "3  {'English': (0.45, 0.4474569146700294, 0.45, 0...  0.194650  \n",
            "4  {'English': (0.59, 0.5989010989010989, 0.59, 0...  0.128155  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5.4: Training Loop (LLaVA without PSO)\n",
        "fixed_params = [1e-4, 0.5, 0.5, 1e-5, 0.3, 512, 16]\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "for fold, (train_idx, test_idx) in enumerate(folds):\n",
        "    train_df, test_df = df.iloc[train_idx], df.iloc[test_idx]\n",
        "    train_dataset = MemeDataset(train_df, clip_transform, llava_tokenizer)\n",
        "    test_dataset = MemeDataset(test_df, clip_transform, llava_tokenizer)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=min(int(fixed_params[6]), len(train_dataset)), shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=min(int(fixed_params[6]), len(test_dataset)))\n",
        "    model = LLaVAModel(fixed_params).to(device)\n",
        "    optimizer = torch.optim.Adam([{'params': model.proj.parameters(), 'lr': fixed_params[0]*fixed_params[1]}, {'params': model.fc.parameters(), 'lr': fixed_params[0]*fixed_params[2]}], weight_decay=fixed_params[3])\n",
        "    for epoch in range(8):\n",
        "        model.train()\n",
        "        if epoch == 5:\n",
        "            for p in model.proj.parameters():\n",
        "                p.requires_grad = True\n",
        "            for p in model.fc.parameters():\n",
        "                p.requires_grad = True\n",
        "        for batch in tqdm(train_loader, desc=f'Fold {fold+1}, Epoch {epoch+1} (No PSO)'):\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "                loss = nn.CrossEntropyLoss()(logits, batch['label'].to(device))\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/Thesis/output/llava_no_pso_fold{fold}.pt')\n",
        "# Train LLaVA with fixed hyperparameters."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "__pn_i2bqH4m",
        "outputId": "61638b84-edb6-4ed8-e637-7f75b1a15c34"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 1, Epoch 1 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.71it/s]\n",
            "Fold 1, Epoch 2 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 1, Epoch 3 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.73it/s]\n",
            "Fold 1, Epoch 4 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 1, Epoch 5 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 1, Epoch 6 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 1, Epoch 7 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 1, Epoch 8 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.70it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 2, Epoch 1 (No PSO): 100%|██████████| 75/75 [00:28<00:00,  2.65it/s]\n",
            "Fold 2, Epoch 2 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.70it/s]\n",
            "Fold 2, Epoch 3 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.71it/s]\n",
            "Fold 2, Epoch 4 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.71it/s]\n",
            "Fold 2, Epoch 5 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.73it/s]\n",
            "Fold 2, Epoch 6 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.74it/s]\n",
            "Fold 2, Epoch 7 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.73it/s]\n",
            "Fold 2, Epoch 8 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.70it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 3, Epoch 1 (No PSO): 100%|██████████| 75/75 [00:29<00:00,  2.57it/s]\n",
            "Fold 3, Epoch 2 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.70it/s]\n",
            "Fold 3, Epoch 3 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.71it/s]\n",
            "Fold 3, Epoch 4 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 3, Epoch 5 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 3, Epoch 6 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 3, Epoch 7 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.71it/s]\n",
            "Fold 3, Epoch 8 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.71it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 4, Epoch 1 (No PSO): 100%|██████████| 75/75 [00:28<00:00,  2.68it/s]\n",
            "Fold 4, Epoch 2 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.71it/s]\n",
            "Fold 4, Epoch 3 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.73it/s]\n",
            "Fold 4, Epoch 4 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.73it/s]\n",
            "Fold 4, Epoch 5 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 4, Epoch 6 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.69it/s]\n",
            "Fold 4, Epoch 7 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.74it/s]\n",
            "Fold 4, Epoch 8 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.74it/s]\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 5, Epoch 1 (No PSO): 100%|██████████| 75/75 [00:28<00:00,  2.66it/s]\n",
            "Fold 5, Epoch 2 (No PSO): 100%|██████████| 75/75 [00:28<00:00,  2.68it/s]\n",
            "Fold 5, Epoch 3 (No PSO): 100%|██████████| 75/75 [00:28<00:00,  2.66it/s]\n",
            "Fold 5, Epoch 4 (No PSO): 100%|██████████| 75/75 [00:28<00:00,  2.67it/s]\n",
            "Fold 5, Epoch 5 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.70it/s]\n",
            "Fold 5, Epoch 6 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 5, Epoch 7 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n",
            "Fold 5, Epoch 8 (No PSO): 100%|██████████| 75/75 [00:27<00:00,  2.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5.5: Evaluation (LLaVA without PSO)\n",
        "llava_no_pso_results = []\n",
        "for fold, (_, test_idx) in enumerate(folds):\n",
        "    test_df = df.iloc[test_idx]\n",
        "    print(f\"Fold {fold+1} test set language distribution:\\n{test_df['language'].value_counts()}\")\n",
        "    test_dataset = MemeDataset(test_df, clip_transform, llava_tokenizer)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=min(int(fixed_params[6]), len(test_dataset)))\n",
        "    model = LLaVAModel(fixed_params).to(device)\n",
        "    model.load_state_dict(torch.load(f'/content/drive/MyDrive/Thesis/output/llava_no_pso_fold{fold}.pt'))\n",
        "    acc, prec, rec, f1, auc = evaluate(model, test_loader)\n",
        "    lang_results = {}\n",
        "    for i, lang in enumerate(['English', 'Igbo', 'Yoruba', 'Hausa']):\n",
        "        lang_df = test_df[test_df['language'] == i]\n",
        "        if len(lang_df) > 0:\n",
        "            lang_dataset = MemeDataset(lang_df, clip_transform, llava_tokenizer)\n",
        "            lang_loader = DataLoader(lang_dataset, batch_size=min(int(fixed_params[6]), len(lang_df)))\n",
        "            try:\n",
        "                metrics = evaluate(model, lang_loader)\n",
        "                lang_results[lang] = metrics\n",
        "                print(f\"Fold {fold+1}, {lang}: acc={metrics[0]:.4f}, prec={metrics[1]:.4f}, rec={metrics[2]:.4f}, f1={metrics[3]:.4f}, auc={metrics[4]:.4f}, samples={len(lang_df)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error evaluating {lang} in fold {fold+1}: {e}\")\n",
        "                lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "        else:\n",
        "            print(f\"No samples for {lang} in fold {fold+1}\")\n",
        "            lang_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "    llava_no_pso_results.append({\n",
        "        'fold': fold+1,\n",
        "        'acc': acc,\n",
        "        'prec': prec,\n",
        "        'rec': rec,\n",
        "        'f1': f1,\n",
        "        'auc': auc,\n",
        "        'lang': lang_results,\n",
        "        'f1_std': np.std([lang_results[l][3] for l in lang_results if lang_results[l][3] != 0.0]) if any(lang_results[l][3] != 0.0 for l in lang_results) else 0.0\n",
        "    })\n",
        "# Fallback: Global evaluation for LLaVA without PSO\n",
        "global_no_pso_results = {}\n",
        "for i, lang in enumerate(['English', 'Igbo', 'Yoruba', 'Hausa']):\n",
        "    lang_df = df[df['language'] == i]\n",
        "    if len(lang_df) > 0:\n",
        "        lang_dataset = MemeDataset(lang_df, clip_transform, llava_tokenizer)\n",
        "        lang_loader = DataLoader(lang_dataset, batch_size=min(int(fixed_params[6]), len(lang_df)))\n",
        "        model = LLaVAModel(fixed_params).to(device)\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(f'/content/drive/MyDrive/Thesis/output/llava_no_pso_fold0.pt'))\n",
        "            metrics = evaluate(model, lang_loader)\n",
        "            global_no_pso_results[lang] = metrics\n",
        "            print(f\"Global {lang}: acc={metrics[0]:.4f}, prec={metrics[1]:.4f}, rec={metrics[2]:.4f}, f1={metrics[3]:.4f}, auc={metrics[4]:.4f}, samples={len(lang_df)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error evaluating global {lang}: {e}\")\n",
        "            global_no_pso_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "    else:\n",
        "        print(f\"No global samples for {lang}\")\n",
        "        global_no_pso_results[lang] = (0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "print(\"Global LLaVA no PSO results:\", {k: f\"acc={v[0]:.4f}, prec={v[1]:.4f}, rec={v[2]:.4f}, f1={v[3]:.4f}, auc={v[4]:.4f}\" for k, v in global_no_pso_results.items()})\n",
        "print(pd.DataFrame(llava_no_pso_results))\n",
        "# Save results\n",
        "with open('/content/drive/MyDrive/Thesis/output/llava_no_pso_results.pkl', 'wb') as f:\n",
        "    pickle.dump(llava_no_pso_results, f)\n",
        "with open('/content/drive/MyDrive/Thesis/output/global_no_pso_results.pkl', 'wb') as f:\n",
        "    pickle.dump(global_no_pso_results, f)\n",
        "# Evaluate LLaVA without PSO performance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vtrCCt9StRTb",
        "outputId": "4bac312f-f078-4108-e1b2-14e0f85db765"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "2     67\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1, English: acc=0.5200, prec=0.5201, rec=0.5200, f1=0.5192, auc=0.5160, samples=100\n",
            "Fold 1, Igbo: acc=0.9104, prec=0.9104, rec=0.9104, f1=0.9095, auc=0.9535, samples=67\n",
            "Fold 1, Yoruba: acc=0.8955, prec=0.9019, rec=0.8955, f1=0.8969, auc=0.9713, samples=67\n",
            "Fold 1, Hausa: acc=0.8485, prec=0.8471, rec=0.8485, f1=0.8470, auc=0.9256, samples=66\n",
            "Fold 2 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "3     67\n",
            "2     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2, English: acc=0.5100, prec=0.5100, rec=0.5100, f1=0.5096, auc=0.4812, samples=100\n",
            "Fold 2, Igbo: acc=0.8507, prec=0.8635, rec=0.8507, f1=0.8413, auc=0.9180, samples=67\n",
            "Fold 2, Yoruba: acc=0.9091, prec=0.9091, rec=0.9091, f1=0.9091, auc=0.9697, samples=66\n",
            "Fold 2, Hausa: acc=0.9552, prec=0.9581, rec=0.9552, f1=0.9545, auc=0.9981, samples=67\n",
            "Fold 3 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "1     67\n",
            "2     67\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3, English: acc=0.5700, prec=0.5707, rec=0.5700, f1=0.5689, auc=0.6052, samples=100\n",
            "Fold 3, Igbo: acc=0.8955, prec=0.8970, rec=0.8955, f1=0.8960, auc=0.9674, samples=67\n",
            "Fold 3, Yoruba: acc=0.9254, prec=0.9265, rec=0.9254, f1=0.9257, auc=0.9684, samples=67\n",
            "Fold 3, Hausa: acc=0.9394, prec=0.9394, rec=0.9394, f1=0.9394, auc=0.9434, samples=66\n",
            "Fold 4 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "2     68\n",
            "1     66\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4, English: acc=0.5000, prec=0.5000, rec=0.5000, f1=0.4833, auc=0.4360, samples=100\n",
            "Fold 4, Igbo: acc=0.8485, prec=0.8479, rec=0.8485, f1=0.8446, auc=0.9393, samples=66\n",
            "Fold 4, Yoruba: acc=0.9118, prec=0.9118, rec=0.9118, f1=0.9118, auc=0.9697, samples=68\n",
            "Fold 4, Hausa: acc=0.8636, prec=0.8663, rec=0.8636, f1=0.8591, auc=0.9191, samples=66\n",
            "Fold 5 test set language distribution:\n",
            "language\n",
            "0    100\n",
            "2     68\n",
            "1     66\n",
            "3     66\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5, English: acc=0.5800, prec=0.5812, rec=0.5800, f1=0.5785, auc=0.5960, samples=100\n",
            "Fold 5, Igbo: acc=0.7727, prec=0.7851, rec=0.7727, f1=0.7499, auc=0.9252, samples=66\n",
            "Fold 5, Yoruba: acc=0.9265, prec=0.9340, rec=0.9265, f1=0.9242, auc=0.9905, samples=68\n",
            "Fold 5, Hausa: acc=0.7576, prec=0.7535, rec=0.7576, f1=0.7548, auc=0.8716, samples=66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global English: acc=0.6860, prec=0.6869, rec=0.6860, f1=0.6856, auc=0.7444, samples=500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Igbo: acc=0.9009, prec=0.9015, rec=0.9009, f1=0.8991, auc=0.9656, samples=333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Yoruba: acc=0.9226, prec=0.9226, rec=0.9226, f1=0.9226, auc=0.9844, samples=336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Hausa: acc=0.9063, prec=0.9059, rec=0.9063, f1=0.9057, auc=0.9632, samples=331\n",
            "Global LLaVA no PSO results: {'English': 'acc=0.6860, prec=0.6869, rec=0.6860, f1=0.6856, auc=0.7444', 'Igbo': 'acc=0.9009, prec=0.9015, rec=0.9009, f1=0.8991, auc=0.9656', 'Yoruba': 'acc=0.9226, prec=0.9226, rec=0.9226, f1=0.9226, auc=0.9844', 'Hausa': 'acc=0.9063, prec=0.9059, rec=0.9063, f1=0.9057, auc=0.9632'}\n",
            "   fold       acc      prec       rec        f1       auc  \\\n",
            "0     1  0.763333  0.764385  0.763333  0.763782  0.853871   \n",
            "1     2  0.773333  0.771581  0.773333  0.771889  0.849676   \n",
            "2     3  0.803333  0.805958  0.803333  0.804204  0.889828   \n",
            "3     4  0.750000  0.748948  0.750000  0.742876  0.834815   \n",
            "4     5  0.740000  0.737500  0.740000  0.733681  0.845046   \n",
            "\n",
            "                                                lang    f1_std  \n",
            "0  {'English': (0.52, 0.5201288244766505, 0.52, 0...  0.159865  \n",
            "1  {'English': (0.51, 0.5100361300682457, 0.51, 0...  0.174480  \n",
            "2  {'English': (0.57, 0.5707070707070706, 0.57, 0...  0.152995  \n",
            "3  {'English': (0.5, 0.5, 0.5, 0.4832575444398512...  0.170099  \n",
            "4  {'English': (0.58, 0.5811688311688311, 0.58, 0...  0.122233  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6.1: Model Comparison\n",
        "# Load results\n",
        "with open('/content/drive/MyDrive/Thesis/output/results.pkl', 'rb') as f:\n",
        "    results = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Thesis/output/llava_pso_results.pkl', 'rb') as f:\n",
        "    llava_pso_results = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Thesis/output/llava_no_pso_results.pkl', 'rb') as f:\n",
        "    llava_no_pso_results = pickle.load(f)\n",
        "\n",
        "# Compute mean metrics across folds\n",
        "baseline_metrics = {\n",
        "    'Model': 'Baseline',\n",
        "    'Acc': np.mean([r['acc'] for r in results]),\n",
        "    'Prec': np.mean([r['prec'] for r in results]),\n",
        "    'Rec': np.mean([r['rec'] for r in results]),\n",
        "    'F1': np.mean([r['f1'] for r in results]),\n",
        "    'AUC': np.mean([r['auc'] for r in results]),\n",
        "    'F1_Std': np.mean([r['f1_std'] for r in results])\n",
        "}\n",
        "llava_pso_metrics = {\n",
        "    'Model': 'LLaVA (PSO)',\n",
        "    'Acc': np.mean([r['acc'] for r in llava_pso_results]),\n",
        "    'Prec': np.mean([r['prec'] for r in llava_pso_results]),\n",
        "    'Rec': np.mean([r['rec'] for r in llava_pso_results]),\n",
        "    'F1': np.mean([r['f1'] for r in llava_pso_results]),\n",
        "    'AUC': np.mean([r['auc'] for r in llava_pso_results]),\n",
        "    'F1_Std': np.mean([r['f1_std'] for r in llava_pso_results])\n",
        "}\n",
        "llava_no_pso_metrics = {\n",
        "    'Model': 'LLaVA (No PSO)',\n",
        "    'Acc': np.mean([r['acc'] for r in llava_no_pso_results]),\n",
        "    'Prec': np.mean([r['prec'] for r in llava_no_pso_results]),\n",
        "    'Rec': np.mean([r['rec'] for r in llava_no_pso_results]),\n",
        "    'F1': np.mean([r['f1'] for r in llava_no_pso_results]),\n",
        "    'AUC': np.mean([r['auc'] for r in llava_no_pso_results]),\n",
        "    'F1_Std': np.mean([r['f1_std'] for r in llava_no_pso_results])\n",
        "}\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame([baseline_metrics, llava_no_pso_metrics, llava_pso_metrics])\n",
        "print(\"\\nModel Comparison Table:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# Perform paired t-tests\n",
        "baseline_f1 = [r['f1'] for r in results]\n",
        "llava_pso_f1 = [r['f1'] for r in llava_pso_results]\n",
        "llava_no_pso_f1 = [r['f1'] for r in llava_no_pso_results]\n",
        "\n",
        "# T-test: Baseline vs. LLaVA (PSO)\n",
        "t_stat1, p_val1 = ttest_rel(baseline_f1, llava_pso_f1)\n",
        "print(f\"\\nT-test (Baseline vs. LLaVA PSO): t={t_stat1:.4f}, p={p_val1:.4f}\")\n",
        "if p_val1 < 0.05:\n",
        "    print(\"Significant difference between Baseline and LLaVA (PSO) F1 scores (p < 0.05)\")\n",
        "else:\n",
        "    print(\"No significant difference between Baseline and LLaVA (PSO) F1 scores (p >= 0.05)\")\n",
        "\n",
        "# T-test: LLaVA (PSO) vs. LLaVA (No PSO)\n",
        "t_stat2, p_val2 = ttest_rel(llava_pso_f1, llava_no_pso_f1)\n",
        "print(f\"T-test (LLaVA PSO vs. LLaVA No PSO): t={t_stat2:.4f}, p={p_val2:.4f}\")\n",
        "if p_val2 < 0.05:\n",
        "    print(\"Significant difference between LLaVA (PSO) and LLaVA (No PSO) F1 scores (p < 0.05)\")\n",
        "else:\n",
        "    print(\"No significant difference between LLaVA (PSO) and LLaVA (No PSO) F1 scores (p >= 0.05)\")\n",
        "\n",
        "# Save comparison\n",
        "with open('/content/drive/MyDrive/Thesis/output/model_comparison.pkl', 'wb') as f:\n",
        "    pickle.dump(comparison_df, f)\n",
        "# Compare model performance with statistical significance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAUa8KV3uHUf",
        "outputId": "8cdf72ae-c8ae-4333-ba6d-fdf354b0a6bb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Comparison Table:\n",
            "            Model       Acc      Prec       Rec        F1       AUC    F1_Std\n",
            "0        Baseline  0.746667  0.753142  0.746667  0.746799  0.840491  0.243346\n",
            "1  LLaVA (No PSO)  0.766000  0.765674  0.766000  0.763286  0.854647  0.155934\n",
            "2     LLaVA (PSO)  0.761333  0.763964  0.761333  0.761180  0.861873  0.176330\n",
            "\n",
            "T-test (Baseline vs. LLaVA PSO): t=-1.4600, p=0.2181\n",
            "No significant difference between Baseline and LLaVA (PSO) F1 scores (p >= 0.05)\n",
            "T-test (LLaVA PSO vs. LLaVA No PSO): t=-0.1908, p=0.8580\n",
            "No significant difference between LLaVA (PSO) and LLaVA (No PSO) F1 scores (p >= 0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6.2: Cross-Lingual and Fairness Analysis\n",
        "# Load global results\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "with open('/content/drive/MyDrive/Thesis/output/global_lang_results.pkl', 'rb') as f:\n",
        "    global_lang_results = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Thesis/output/global_llava_results.pkl', 'rb') as f:\n",
        "    global_llava_results = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/Thesis/output/global_no_pso_results.pkl', 'rb') as f:\n",
        "    global_no_pso_results = pickle.load(f)\n",
        "\n",
        "# Extract F1 scores for each language\n",
        "languages = ['English', 'Igbo', 'Yoruba', 'Hausa']\n",
        "cross_lingual_f1 = {\n",
        "    'Language': languages,\n",
        "    'Baseline F1': [global_lang_results[lang][3] for lang in languages],\n",
        "    'LLaVA (No PSO) F1': [global_no_pso_results[lang][3] for lang in languages],\n",
        "    'LLaVA (PSO) F1': [global_llava_results[lang][3] for lang in languages]\n",
        "}\n",
        "cross_lingual_df = pd.DataFrame(cross_lingual_f1)\n",
        "print(\"\\nCross-Lingual F1 Scores:\")\n",
        "print(cross_lingual_df)\n",
        "\n",
        "# Compute fairness (F1 standard deviation across languages)\n",
        "fairness_metrics = {\n",
        "    'Model': ['Baseline', 'LLaVA (No PSO)', 'LLaVA (PSO)'],\n",
        "    'F1_Std Across Languages': [\n",
        "        np.std([global_lang_results[lang][3] for lang in languages]),\n",
        "        np.std([global_no_pso_results[lang][3] for lang in languages]),\n",
        "        np.std([global_llava_results[lang][3] for lang in languages])\n",
        "    ]\n",
        "}\n",
        "fairness_df = pd.DataFrame(fairness_metrics)\n",
        "print(\"\\nFairness (F1 Std Across Languages):\")\n",
        "print(fairness_df)\n",
        "\n",
        "# Bar chart for cross-lingual F1 scores\n",
        "# The chartjs syntax is not supported directly in Colab code cells.\n",
        "# To generate a chart, you would typically use a library like matplotlib or seaborn."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MN1_mjT0HEF",
        "outputId": "9e90ad0d-d1e7-4bba-9975-22af68b50702"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-Lingual F1 Scores:\n",
            "  Language  Baseline F1  LLaVA (No PSO) F1  LLaVA (PSO) F1\n",
            "0  English     0.845970           0.685637        0.807889\n",
            "1     Igbo     0.978913           0.899131        0.929502\n",
            "2   Yoruba     0.985073           0.922619        0.982029\n",
            "3    Hausa     0.987891           0.905654        0.929494\n",
            "\n",
            "Fairness (F1 Std Across Languages):\n",
            "            Model  F1_Std Across Languages\n",
            "0        Baseline                 0.059839\n",
            "1  LLaVA (No PSO)                 0.097157\n",
            "2     LLaVA (PSO)                 0.063944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6.3: Global Confusion Matrices and Visualizations\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs('/content/drive/MyDrive/Thesis/output', exist_ok=True)\n",
        "\n",
        "# Load results\n",
        "try:\n",
        "    with open('/content/drive/MyDrive/Thesis/output/results.pkl', 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "    with open('/content/drive/MyDrive/Thesis/output/llava_pso_results.pkl', 'rb') as f:\n",
        "        llava_pso_results = pickle.load(f)\n",
        "    with open('/content/drive/MyDrive/Thesis/output/llava_no_pso_results.pkl', 'rb') as f:\n",
        "        llava_no_pso_results = pickle.load(f)\n",
        "    with open('/content/drive/MyDrive/Thesis/output/global_lang_results.pkl', 'rb') as f:\n",
        "        global_lang_results = pickle.load(f)\n",
        "    with open('/content/drive/MyDrive/Thesis/output/global_llava_results.pkl', 'rb') as f:\n",
        "        global_llava_results = pickle.load(f)\n",
        "    with open('/content/drive/MyDrive/Thesis/output/global_no_pso_results.pkl', 'rb') as f:\n",
        "        global_no_pso_results = pickle.load(f)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Missing result file - {e}\")\n",
        "    raise\n",
        "\n",
        "# Function to compute global confusion matrix\n",
        "def compute_global_cm(model, df, transform, tokenizer, device):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    dataset = MemeDataset(df, transform, tokenizer)\n",
        "    loader = DataLoader(dataset, batch_size=8)\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                logits = model(batch['image'].to(device), batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "                preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "                labels.extend(batch['label'].cpu().numpy())\n",
        "        return confusion_matrix(labels, preds, labels=[0, 1])\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error during global confusion matrix computation: {e}\")\n",
        "        return np.zeros((2, 2))\n",
        "\n",
        "# Compute global confusion matrices\n",
        "models = [\n",
        "    ('Baseline', BaselineModel, resnet_transform, baseline_tokenizer, '/content/drive/MyDrive/Thesis/output/model_fold0.pt'),\n",
        "    ('LLaVA (PSO)', lambda: LLaVAModel(best_params), clip_transform, llava_tokenizer, '/content/drive/MyDrive/Thesis/output/llava_pso_fold0.pt'),\n",
        "    ('LLaVA (No PSO)', lambda: LLaVAModel(fixed_params), clip_transform, llava_tokenizer, '/content/drive/MyDrive/Thesis/output/llava_no_pso_fold0.pt')\n",
        "]\n",
        "global_cms = {}\n",
        "\n",
        "for model_name, model_fn, transform, tokenizer, model_path in models:\n",
        "    try:\n",
        "        model = model_fn().to(device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {model_name} model: {e}\")\n",
        "        continue\n",
        "    global_cms[model_name] = compute_global_cm(model, df, transform, tokenizer, device)\n",
        "    print(f\"\\n{model_name} Global Confusion Matrix:\\n{global_cms[model_name]}\")\n",
        "\n",
        "    # Plot global confusion matrix as heatmap\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(global_cms[model_name], annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=['Non-Hate', 'Hate'], yticklabels=['Non-Hate', 'Hate'])\n",
        "    plt.title(f'{model_name} Global Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.savefig(f'/content/drive/MyDrive/Thesis/output/cm_{model_name.replace(\" \", \"_\").lower()}_global.png')\n",
        "    plt.close()\n",
        "\n",
        "# AUC Bar Chart (Matplotlib)\n",
        "languages = ['English', 'Igbo', 'Yoruba', 'Hausa']\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(languages))\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x - bar_width, [global_lang_results[lang][4] for lang in languages], bar_width, label='Baseline', color='#1f77b4')\n",
        "plt.bar(x, [global_no_pso_results[lang][4] for lang in languages], bar_width, label='LLaVA (No PSO)', color='#ff7f0e')\n",
        "plt.bar(x + bar_width, [global_llava_results[lang][4] for lang in languages], bar_width, label='LLaVA (PSO)', color='#2ca02c')\n",
        "plt.xlabel('Language')\n",
        "plt.ylabel('AUC Score')\n",
        "plt.title('Cross-Lingual AUC Scores by Model')\n",
        "plt.xticks(x, languages)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/Thesis/output/auc_comparison.png')\n",
        "plt.close()\n",
        "\n",
        "# F1 Std Line Chart (Matplotlib)\n",
        "f1_std_data = {\n",
        "    'Baseline': [r['f1_std'] for r in results],\n",
        "    'LLaVA (No PSO)': [r['f1_std'] for r in llava_no_pso_results],\n",
        "    'LLaVA (PSO)': [r['f1_std'] for r in llava_pso_results]\n",
        "}\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 6), f1_std_data['Baseline'], marker='o', label='Baseline', color='#1f77b4')\n",
        "plt.plot(range(1, 6), f1_std_data['LLaVA (No PSO)'], marker='s', label='LLaVA (No PSO)', color='#ff7f0e')\n",
        "plt.plot(range(1, 6), f1_std_data['LLaVA (PSO)'], marker='^', label='LLaVA (PSO)', color='#2ca02c')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('F1 Standard Deviation')\n",
        "plt.title('F1 Standard Deviation Across Folds')\n",
        "plt.xticks(range(1, 6))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/Thesis/output/f1_std_comparison.png')\n",
        "plt.close()\n",
        "\n",
        "# Save global confusion matrices\n",
        "with open('/content/drive/MyDrive/Thesis/output/global_confusion_matrices.pkl', 'wb') as f:\n",
        "    pickle.dump(global_cms, f)\n",
        "# Compute global confusion matrices and visualize with Matplotlib."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgZAX4ha1ZDI",
        "outputId": "568e6e8d-26b2-4cb9-ad1c-68aaa1ff4ea1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clearing GPU cache before ResNet50...\n",
            "Loading ResNet50...\n",
            "ResNet50 loaded successfully\n",
            "Clearing GPU cache before DistilBERT...\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully\n",
            "\n",
            "Baseline Global Confusion Matrix:\n",
            "[[861  39]\n",
            " [ 54 546]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LLaVA (PSO) Global Confusion Matrix:\n",
            "[[850  50]\n",
            " [ 98 502]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LLaVA (No PSO) Global Confusion Matrix:\n",
            "[[779 121]\n",
            " [126 474]]\n"
          ]
        }
      ]
    }
  ]
}